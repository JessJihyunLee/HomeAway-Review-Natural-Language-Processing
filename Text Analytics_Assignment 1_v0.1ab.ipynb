{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "%pylab inline\n",
    "import csv\n",
    "from collections import Counter\n",
    "import random\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from string import punctuation\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import re\n",
    "from patsy import dmatrices\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data = pd.read_csv('Train_rev1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taking random 2500 data points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data = job_data.sample(n=2500, random_state = 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1. What are the top 5 parts of speech in the job descriptions? How frequently do they appear? How do these numbers change if you exclude stopwords? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Word corpus:\n",
    "job_data_list = job_data[\"FullDescription\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_words = []\n",
    "for item in job_data_list:\n",
    "    words = []\n",
    "    words = nltk.word_tokenize(item.lower())\n",
    "    tokenized_words = tokenized_words + words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_words_string = \" \".join(str(x) for x in tokenized_words)\n",
    "for p in punctuation:\n",
    "    tokenized_words_string=tokenized_words_string.replace(p,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS Tagging\n",
    "job_descriptions_tagged = nltk.pos_tag(nltk.word_tokenize(tokenized_words_string))\n",
    "#tokenized_words_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 156791), ('JJ', 70755), ('IN', 65478), ('DT', 50604), ('NNS', 50447)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the frequency of tags\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in job_descriptions_tagged)\n",
    "tag_fd.most_common()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common parts of speech with removing stop words are nouns, adjective, preposition, Determiner, and Noun plural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "word_tokenize = nltk.word_tokenize(tokenized_words_string)\n",
    "filtered_sentence = [w for w in word_tokenize if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 151266), ('JJ', 72996), ('NNS', 49954), ('VBG', 25541), ('VBP', 16847)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_words_without_stopwords = \" \".join(str(x) for x in filtered_sentence)\n",
    "\n",
    "job_descriptions_tagged_without_stopwords = nltk.pos_tag(nltk.word_tokenize(tokenized_words_without_stopwords))\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in job_descriptions_tagged_without_stopwords)\n",
    "tag_fd.most_common()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top most frequent POS are now noun, adjective, plural noun, verb and verb - singular present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2. Does this data support Zipf’s law? Plot the most common 100 words in the data against the theoretical prediction of the law. For this question, do not remove stopwords. Also do not perform stemming or lemmatization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Word Frequency')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_words = nltk.FreqDist((nltk.word_tokenize(tokenized_words_string)))\n",
    "\n",
    "topwords = all_words.most_common(100)\n",
    "frequency = []\n",
    "for (word, freq) in topwords:\n",
    "    frequency.append(freq)\n",
    "\n",
    "frequency = pd.Series(frequency)\n",
    "\n",
    "# Get the observational rank\n",
    "word_ranking = frequency.rank(method = 'min',ascending =False)\n",
    "\n",
    "# Plot obseravtional and theoritical rank\n",
    "def theoretical_rank(freq):\n",
    "    # We will take the frequency of the words to calculate the theoritical rank using variation of Zipf's Law\n",
    "    rank = math.exp((-1)*(np.log(freq) - np.log(max(word_ranking)*min(frequency))))\n",
    "    return rank\n",
    "\n",
    "# get the theoretical ranks for the frequencies observed\n",
    "theoretical_rank = frequency.map(theoretical_rank)\n",
    "plt.scatter(word_ranking,frequency,color = 'blue', marker = 'x',label = 'Frequency vs observed rank')\n",
    "plt.scatter(theoretical_rank,frequency,color = 'red',marker = 'o',label = 'Frequency vs theoritical rank')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Word Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A3. If we remove stopwords and lemmatize the data, what are the 10 most common words? What are their frequencies?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('work', 5283),\n",
       " ('experience', 5118),\n",
       " ('role', 3163),\n",
       " ('team', 3060),\n",
       " ('client', 2996),\n",
       " ('business', 2864),\n",
       " ('service', 2444),\n",
       " ('skill', 2424),\n",
       " ('sale', 2212),\n",
       " ('within', 2181)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "def get_pos( word ):\n",
    "    w_synsets = wordnet.synsets(word)\n",
    "\n",
    "    pos_counts = Counter()\n",
    "    pos_counts[\"n\"] = len(  [ item for item in w_synsets if item.pos()==\"n\"]  )\n",
    "    pos_counts[\"v\"] = len(  [ item for item in w_synsets if item.pos()==\"v\"]  )\n",
    "    pos_counts[\"a\"] = len(  [ item for item in w_synsets if item.pos()==\"a\"]  )\n",
    "    pos_counts[\"r\"] = len(  [ item for item in w_synsets if item.pos()==\"r\"]  )\n",
    "    \n",
    "    most_common_pos_list = pos_counts.most_common(3)\n",
    "    return most_common_pos_list[0][0]\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "word_lematized = [wordnet_lemmatizer.lemmatize(w,pos=get_pos(w)) for w in filtered_sentence] \n",
    "\n",
    "word_lematized_words = Counter(word_lematized)\n",
    "most_common_words = word_lematized_words.most_common()\n",
    "most_common_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top words after removing stop words and stemming are work, experience, role, team, client, business, service, skill, sale and within"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B (predict salary from job description; the idea here is to test the predictive power of text and compare it with that of numeric data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us first create our data frame and clean up some of the data so that we can use it for prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a column for high/low salaries - We wil consider the top 25th percentile ( >75th quantile) salaries as high and remainig as low salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "job_data['Salary'] = 0\n",
    "job_data['Salary'][job_data['SalaryNormalized']> job_data['SalaryNormalized'].quantile(0.75)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us convert the locations with high living costs to 1 and the other loctions to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlivingcost = ['oxford','uk','the city','greater london','central london','london','south east london',\\\n",
    "                  'winchester', 'cambridge', 'chichester', 'brighon and hove', 'bath', 'southhampton',\\\n",
    "                  'salisbury','canterbury','st albans', 'bristol','lichfield','truro','norwich','chelmsford',\\\n",
    "                  'exeter','york','leicester','gloucester']\n",
    "\n",
    "def living_cost(s):\n",
    "    if s.lower() in highlivingcost:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "job_data['cost_of_living'] = job_data['LocationNormalized'].apply(living_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us clean the job descriptions to remove punctuations and numbers from textua data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removepunc(item):\n",
    "    for p in punctuation:\n",
    "        item = item.replace(p,'')\n",
    "    return item\n",
    "\n",
    "def remove_numbers(s):\n",
    "    return re.sub(\"\\S*\\d\\S*\", \"\", s).strip()\n",
    "\n",
    "def lowerize(x):\n",
    "    return x.lower()\n",
    "\n",
    "job_data['CleanDescription'] = job_data['FullDescription'].apply(removepunc).apply(lowerize).apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B1. Ignore the job descriptions, and train a model to predict high/low salary from all the numeric columns, e.g., part time/full time, contract vs. others, type of job (a lot of dummy variables), location (instead of using a huge number of dummy variables, you can use a list of cities in England with highest cost of living, and create a 0/1 variable which is 1 if the job is in one of those cities, else 0). Use the Naïve Bayes classifier. What is the accuracy of your model?**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us remove the columns which we do not need for the prediction \n",
    "job_data_for_prediction = job_data[['ContractType','ContractTime','Category','Salary',\\\n",
    "                                    'cost_of_living']]\n",
    "job_data_dummies = pd.get_dummies(job_data_for_prediction)\n",
    "column_names = job_data_dummies.loc[:, job_data_dummies.columns != 'Salary'].columns.values\n",
    "formula = 'Salary ~ 0 + {}'.format(' + '.join(['Q(\"{}\")'.format(x) for x in column_names]))\n",
    "\n",
    "Y, X = dmatrices(formula, job_data_dummies, return_type='dataframe')\n",
    "y = Y['Salary'].values\n",
    "\n",
    "#Split the data into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7813333333333333"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(y_test) - y_test.sum()) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multinomial Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Numeric Only Model with Multinomial Naive Bayes is: 0.7826666666666666\n",
      "AUC of Numeric Only Model with Multinomial Naive Bayes is: 0.5513506201614916\n",
      "Confusion Matrix of Numeric Only Model with Multinomial Naive Bayes is:\n",
      " [[564  22]\n",
      " [141  23]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "model = naive_bayes.MultinomialNB()\n",
    "# Fit the model\n",
    "result = model.fit(X_train, y_train)\n",
    "# Predict the model on test data\n",
    "from sklearn import metrics\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "#Printing Accuracy, AUC and Confusion Matrix\n",
    "print ('Accuracy of Numeric Only Model with Multinomial Naive Bayes is:', metrics.accuracy_score(y_test, prediction))\n",
    "print ('AUC of Numeric Only Model with Multinomial Naive Bayes is:', metrics.roc_auc_score(y_test, prediction))\n",
    "print ('Confusion Matrix of Numeric Only Model with Multinomial Naive Bayes is:\\n',\\\n",
    "       metrics.confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bernoulli Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Numeric Only Model with Bernoulli Naive Bayes is: 0.7773333333333333\n",
      "AUC of Numeric Only Model with Bernoulli Naive Bayes is: 0.5742841088820445\n",
      "Confusion Matrix of Numeric Only Model with Bernoulli Naive Bayes is:\n",
      " [[548  38]\n",
      " [129  35]]\n"
     ]
    }
   ],
   "source": [
    "model = naive_bayes.BernoulliNB()\n",
    "# Fit the model\n",
    "result = model.fit(X_train, y_train)\n",
    "# Predict the model on test data\n",
    "from sklearn import metrics\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "#Printing Accuracy, AUC and Confusion Matrix\n",
    "print ('Accuracy of Numeric Only Model with Bernoulli Naive Bayes is:', metrics.accuracy_score(y_test, prediction))\n",
    "print ('AUC of Numeric Only Model with Bernoulli Naive Bayes is:', metrics.roc_auc_score(y_test, prediction))\n",
    "print ('Confusion Matrix of Numeric Only Model with Bernoulli Naive Bayes is:\\n',metrics.confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B2. Create a classification model with all words and the bag-of-words approach. How accurate is the model (show the confusion matrix)?** \n",
    "\n",
    "**Also show the top 10 words (excluding stopwords) that are most indicative of (i) high salary, and (ii) low salary. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bernoulli Naive Bayes (Only Job Descriptions)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting top most common words (features)\n",
    "word_features =[]\n",
    "for (word,freq) in most_common_words:\n",
    "    word_features.append(word)\n",
    "word_top_features = word_features [:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy percent: 78.26666666666667\n",
      "Most Informative Features\n",
      "           architectural = True                1 : 0      =     14.7 : 1.0\n",
      "                 ethical = True                1 : 0      =     12.7 : 1.0\n",
      "              enterprise = True                1 : 0      =     11.1 : 1.0\n",
      "                   stack = True                1 : 0      =     10.8 : 1.0\n",
      "                  devise = True                1 : 0      =     10.8 : 1.0\n",
      "                 startup = True                1 : 0      =     10.8 : 1.0\n",
      "               translate = True                1 : 0      =     10.8 : 1.0\n",
      "              sufficient = True                1 : 0      =     10.8 : 1.0\n",
      "                    tier = True                1 : 0      =     10.8 : 1.0\n",
      "               genuinely = True                1 : 0      =      8.8 : 1.0\n",
      "                 combine = True                1 : 0      =      8.8 : 1.0\n",
      "                   video = True                1 : 0      =      8.8 : 1.0\n",
      "                    feed = True                1 : 0      =      8.8 : 1.0\n",
      "                 feature = True                1 : 0      =      8.8 : 1.0\n",
      "                   agile = True                1 : 0      =      8.3 : 1.0\n",
      "             credibility = True                1 : 0      =      7.1 : 1.0\n",
      "               telephone = True                0 : 1      =      7.1 : 1.0\n",
      "          administrative = True                0 : 1      =      6.9 : 1.0\n",
      "                   pitch = True                1 : 0      =      6.9 : 1.0\n",
      "                     app = True                1 : 0      =      6.9 : 1.0\n",
      "                presales = True                1 : 0      =      6.9 : 1.0\n",
      "                     arm = True                1 : 0      =      6.9 : 1.0\n",
      "                 circuit = True                1 : 0      =      6.9 : 1.0\n",
      "             mathematics = True                1 : 0      =      6.9 : 1.0\n",
      "             stakeholder = True                1 : 0      =      6.6 : 1.0\n",
      "               induction = True                0 : 1      =      6.5 : 1.0\n",
      "             institution = True                1 : 0      =      6.5 : 1.0\n",
      "                 nuclear = True                1 : 0      =      6.5 : 1.0\n",
      "               architect = True                1 : 0      =      6.5 : 1.0\n",
      "                  relate = True                1 : 0      =      6.5 : 1.0\n",
      "              transition = True                1 : 0      =      6.5 : 1.0\n",
      "             methodology = True                1 : 0      =      6.5 : 1.0\n",
      "              connection = True                1 : 0      =      6.3 : 1.0\n",
      "                 absence = True                0 : 1      =      6.2 : 1.0\n",
      "             hardworking = True                0 : 1      =      6.2 : 1.0\n",
      "              deployment = True                1 : 0      =      6.1 : 1.0\n",
      "                 elderly = True                0 : 1      =      6.0 : 1.0\n",
      "                   hotel = True                0 : 1      =      5.8 : 1.0\n",
      "                purchase = True                0 : 1      =      5.8 : 1.0\n",
      "              contractor = True                1 : 0      =      5.7 : 1.0\n",
      "                   phone = True                0 : 1      =      5.7 : 1.0\n",
      "                   cycle = True                1 : 0      =      5.6 : 1.0\n",
      "                 vehicle = True                0 : 1      =      5.5 : 1.0\n",
      "              generalist = True                1 : 0      =      5.3 : 1.0\n",
      "                    mean = True                1 : 0      =      5.3 : 1.0\n",
      "                    span = True                1 : 0      =      5.3 : 1.0\n",
      "                  relish = True                1 : 0      =      5.3 : 1.0\n",
      "             feasibility = True                1 : 0      =      5.3 : 1.0\n",
      "                   embed = True                1 : 0      =      5.3 : 1.0\n",
      "                 premier = True                1 : 0      =      5.3 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "job_data['description_jobcategory_tuple'] = list(zip(job_data.FullDescription, job_data.Salary))\n",
    "def find_features(s):\n",
    "    words = nltk.word_tokenize(s)\n",
    "    features = {}\n",
    "    for w in word_top_features:\n",
    "        features[w] = (w in words)\n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev),Salary) for (rev, Salary) in job_data['description_jobcategory_tuple']]\n",
    "training_set, testing_set, = train_test_split(featuresets, test_size=0.3, random_state=99)\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Classifier accuracy percent:\",(nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "print (classifier.show_most_informative_features(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top words indicative of high salary are - architectural, ethical, enterprise, stack, devise, startup, translate, sufficient, tier, geniuenly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 words indicative of low salary are - telephone, administrative, induction, absence, hardworking, elderly, hotel, purchase, phone, vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Text Only Model with Bernoulli Naive Bayes is:\n",
      " [[479 107]\n",
      " [ 56 108]]\n"
     ]
    }
   ],
   "source": [
    "#Calculating the predicted salary for test data\n",
    "def predicted_salary(word_dict):\n",
    "    return classifier.classify(word_dict)\n",
    "\n",
    "salary_pred = [predicted_salary(word_dict) for (word_dict, Salary) in testing_set]\n",
    "salary_true = [Salary for (word_dict, Salary) in testing_set]\n",
    "\n",
    "#Creating confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print ('Confusion Matrix of Text Only Model with Bernoulli Naive Bayes is:\\n',confusion_matrix(salary_true, salary_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B3. Train a “hybrid” model to predict high/low salary using both numeric and text data. Show the accuracy of the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, analyzer='word', stop_words='english')\n",
    "job_description_words = vectorizer.fit_transform(job_data.pop('CleanDescription')).toarray()\n",
    "\n",
    "#Converting the tf-idf scores to 1's and 0's so that the word features can be used in Bernoullis Naive Bayes\n",
    "job_description_words = np.where(job_description_words > 0, 1, 0)\n",
    "word_features_df = pd.DataFrame(job_description_words, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Hybrid Model with Bernoulli Naive Bayes is: 0.784\n",
      "AUC of Hybrid Model with Bernoulli Naive Bayes is: 0.6069070803762997\n",
      "Confusion Matrix of Hybrid Model with Bernoulli Naive Bayes is:\n",
      " [[540  44]\n",
      " [118  48]]\n"
     ]
    }
   ],
   "source": [
    "#Getting all the numeric variables\n",
    "numeric_variables = X.reset_index().drop(columns = 'index')\n",
    "\n",
    "#Combining the numerical and textual features into one data frame\n",
    "combined_df = pd.concat([word_features_df,numeric_variables],axis = 1)\n",
    "\n",
    "#Splitting the data into train and test\n",
    "random.seed(99)\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_df, y, test_size=0.3)\n",
    "model = naive_bayes.BernoulliNB()\n",
    "\n",
    "#Fit the model\n",
    "result = model.fit(X_train, y_train)\n",
    "\n",
    "#Predict the model on test data\n",
    "from sklearn import metrics\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "#Printing Accuracy, AUC and Confusion Matrix\n",
    "print ('Accuracy of Hybrid Model with Bernoulli Naive Bayes is:', metrics.accuracy_score(y_test, prediction))\n",
    "print ('AUC of Hybrid Model with Bernoulli Naive Bayes is:', metrics.roc_auc_score(y_test, prediction))\n",
    "print ('Confusion Matrix of Hybrid Model with Bernoulli Naive Bayes is:\\n',metrics.confusion_matrix(y_test, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
